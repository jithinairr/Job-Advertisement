{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: Padinjarekolath Jithin Nair\n",
    "#### Student ID: s3952043\n",
    "\n",
    "Date: 25/09/2023\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* sklearn\n",
    "* numpy\n",
    "* os\n",
    "* nltk\n",
    "* gensim\n",
    "* warnings\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### Task 2 Introduction:\n",
    "\n",
    "Task 2 focuses on creating feature representations for job advertisement descriptions. We generate count vectors based on Task 1's vocabulary and search meaningful data in word embeddings using language models. This gives us TF-IDF weighted and unweighted vectors, providing diverse ways to understand job ads.\n",
    "\n",
    "#### Task 3 Introduction:\n",
    "\n",
    "Task 3 shifts to job ad classification. We aim to classify ads into categories. Two key questions guide our exploration: 1) which language model from Task 2 performs best with our ML model, and 2) does including job titles improve accuracy? These questions drive our model-building and evaluation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Job Advertisement Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the preprocessed job advertisements\n",
    "preprocessed_ads = pd.read_csv(\"preprocessed_ads.csv\", header=None, names=[\"Webindex\", \"Description\"])\n",
    "\n",
    "# Load the vocabulary created in Task 1\n",
    "vocabulary = {}\n",
    "with open(\"vocab.txt\", \"r\", encoding=\"utf-8\") as vocab_file:\n",
    "    for line in vocab_file:\n",
    "        word, index = line.strip().split(\":\")\n",
    "        vocabulary[word] = int(index)\n",
    "\n",
    "# Initialize a CountVectorizer with the custom vocabulary\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(), vocabulary=vocabulary)\n",
    "\n",
    "# Transform the descriptions into count vectors\n",
    "count_vectors = count_vectorizer.transform(preprocessed_ads[\"Description\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models based on word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "word_embedding_model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Define a regular expression pattern for tokenization (should match the pattern used in Task 1)\n",
    "pattern = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "tokenizer = re.compile(pattern)\n",
    "\n",
    "custom_tokenizer = tokenizer.findall\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer with your custom tokenizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "\n",
    "# Fit the TF-IDF Vectorizer on your preprocessed descriptions\n",
    "tfidf_vectorizer.fit(preprocessed_ads[\"Description\"])\n",
    "\n",
    "# Initialize lists to store TF-IDF weighted and unweighted vectors\n",
    "tfidf_weighted_vectors = []\n",
    "unweighted_vectors = []\n",
    "\n",
    "# Loop through each description\n",
    "for _, description in preprocessed_ads.itertuples(index=False):\n",
    "    # Compute TF-IDF vector\n",
    "    tfidf_vector = tfidf_vectorizer.transform([description])\n",
    "    \n",
    "    # Compute TF-IDF weighted vector representation\n",
    "    weighted_vector = np.mean([tfidf_vector[0, tfidf_vectorizer.vocabulary_[token]] * word_embedding_model[token] \n",
    "                               for token in tokenizer.findall(description) if token in word_embedding_model], axis=0)\n",
    "    \n",
    "    # Compute unweighted vector representation\n",
    "    unweighted_vector = np.mean([word_embedding_model[token] \n",
    "                                 for token in tokenizer.findall(description) if token in word_embedding_model], axis=0)\n",
    "    \n",
    "    # Append the vectors to the respective lists\n",
    "    tfidf_weighted_vectors.append(weighted_vector)\n",
    "    unweighted_vectors.append(unweighted_vector)\n",
    "\n",
    "# Save the TF-IDF weighted vectors to a file (tfidf_weighted_vectors.txt)\n",
    "np.savetxt(\"weighted_vectors.txt\", tfidf_weighted_vectors)\n",
    "\n",
    "# Save the unweighted vectors to a file (unweighted_vectors.txt)\n",
    "np.savetxt(\"unweighted_vectors.txt\", unweighted_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs\n",
    "Save the count vector representation as per spectification.\n",
    "- count_vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the count vectors to a file (count_vectors.txt)\n",
    "with open(\"count_vectors.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for webindex, vector in zip(preprocessed_ads[\"Webindex\"], count_vectors):\n",
    "        non_zero_indices = vector.nonzero()[1]\n",
    "        line = f\"#{webindex},{','.join([f'{index}:{vector[0, index]}' for index in non_zero_indices])}\\n\"\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Job Advertisement Classification\n",
    "\n",
    "#### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Webindex</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial Insurance Underwriter</td>\n",
       "      <td>69092773</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Bond Search Selection Ltd</td>\n",
       "      <td>Our client is a leading Insurer based in Belfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regulatory Policy Manager</td>\n",
       "      <td>71674555</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Michael Page Financial Services</td>\n",
       "      <td>As a Regulatory Policy Manager at a leading Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA to Managing Partner</td>\n",
       "      <td>70758175</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Wells Tobias</td>\n",
       "      <td>A brand new position has arisen within a highl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fixed Income Portfolio Analyst</td>\n",
       "      <td>69564390</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Mason Blake Ltd</td>\n",
       "      <td>This is a newly created position will involve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commercial Finance Analyst</td>\n",
       "      <td>70255258</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Axon Resourcing Ltd</td>\n",
       "      <td>A newly created role for a commercial finance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>European Account Manager (German and English)</td>\n",
       "      <td>66399629</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Positive Selection</td>\n",
       "      <td>Our client is in urgent need of a candidate wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Graduate Sales Executive, Construction Product...</td>\n",
       "      <td>68702817</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Aaron Wallis Sales Recruitment</td>\n",
       "      <td>Graduate Sales Executive, Construction Product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>International Sales Account Manager  German Ma...</td>\n",
       "      <td>66935937</td>\n",
       "      <td>Sales</td>\n",
       "      <td>INTERACTION RECRUITMENT</td>\n",
       "      <td>INTERNATIONAL SALES ACCOUNT MANAGER  managing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Rail Signal Design Team Leader</td>\n",
       "      <td>71812011</td>\n",
       "      <td>Sales</td>\n",
       "      <td>UKStaffsearch</td>\n",
       "      <td>We are currently looking for Rail Signal Desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Eco deal Surveyor / Sales Advisor</td>\n",
       "      <td>69768475</td>\n",
       "      <td>Sales</td>\n",
       "      <td>ENERGYADVICEUK</td>\n",
       "      <td>EXPERIENCED CAVITY WALL AND LOFT SURVEYORS NEE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  Webindex  \\\n",
       "0                     Commercial Insurance Underwriter  69092773   \n",
       "1                            Regulatory Policy Manager  71674555   \n",
       "2                               PA to Managing Partner  70758175   \n",
       "3                       Fixed Income Portfolio Analyst  69564390   \n",
       "4                           Commercial Finance Analyst  70255258   \n",
       "..                                                 ...       ...   \n",
       "771      European Account Manager (German and English)  66399629   \n",
       "772  Graduate Sales Executive, Construction Product...  68702817   \n",
       "773  International Sales Account Manager  German Ma...  66935937   \n",
       "774                     Rail Signal Design Team Leader  71812011   \n",
       "775                  Eco deal Surveyor / Sales Advisor  69768475   \n",
       "\n",
       "               Category                          Company  \\\n",
       "0    Accounting_Finance        Bond Search Selection Ltd   \n",
       "1    Accounting_Finance  Michael Page Financial Services   \n",
       "2    Accounting_Finance                     Wells Tobias   \n",
       "3    Accounting_Finance                  Mason Blake Ltd   \n",
       "4    Accounting_Finance              Axon Resourcing Ltd   \n",
       "..                  ...                              ...   \n",
       "771               Sales               Positive Selection   \n",
       "772               Sales   Aaron Wallis Sales Recruitment   \n",
       "773               Sales          INTERACTION RECRUITMENT   \n",
       "774               Sales                    UKStaffsearch   \n",
       "775               Sales                   ENERGYADVICEUK   \n",
       "\n",
       "                                           Description  \n",
       "0    Our client is a leading Insurer based in Belfa...  \n",
       "1    As a Regulatory Policy Manager at a leading Fi...  \n",
       "2    A brand new position has arisen within a highl...  \n",
       "3    This is a newly created position will involve ...  \n",
       "4    A newly created role for a commercial finance ...  \n",
       "..                                                 ...  \n",
       "771  Our client is in urgent need of a candidate wi...  \n",
       "772  Graduate Sales Executive, Construction Product...  \n",
       "773  INTERNATIONAL SALES ACCOUNT MANAGER  managing ...  \n",
       "774  We are currently looking for Rail Signal Desig...  \n",
       "775  EXPERIENCED CAVITY WALL AND LOFT SURVEYORS NEE...  \n",
       "\n",
       "[776 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "\n",
    "# Initialize a list to store extracted information from all files\n",
    "job_info_list = []\n",
    "\n",
    "# Loop through each job category folder\n",
    "job_folders = [\"Accounting_Finance\", \"Engineering\", \"Healthcare_Nursing\", \"Sales\"]\n",
    "for category_name in job_folders:\n",
    "    category_path = os.path.join(data_folder, category_name)\n",
    "\n",
    "    # Loop through each job advertisement file in the category folder\n",
    "    for file_name in os.listdir(category_path):\n",
    "        if file_name.startswith(\"Job_\") and file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "\n",
    "            # Initialize variables to store extracted values\n",
    "            title = None\n",
    "            webindex = None\n",
    "            company = None\n",
    "            description = None\n",
    "\n",
    "            # Read the job advertisement text from the file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Split the file content into lines\n",
    "            lines = file_content.strip().split('\\n')\n",
    "\n",
    "            # Initialize the category with the current folder name\n",
    "            category = category_name\n",
    "\n",
    "            # Iterate through lines to extract information\n",
    "            for line in lines:\n",
    "                key, value = line.strip().split(': ', 1)\n",
    "                if key == 'Title':\n",
    "                    title = value\n",
    "                elif key == 'Webindex':\n",
    "                    webindex = value\n",
    "                elif key == 'Company':\n",
    "                    company = value\n",
    "                elif key == 'Description':\n",
    "                    description = value\n",
    "\n",
    "            # Store extracted information in a dictionary\n",
    "            job_info = {\n",
    "                'Title': title,\n",
    "                'Webindex': webindex,\n",
    "                'Category': category, \n",
    "                'Company': company,\n",
    "                'Description': description,\n",
    "            }\n",
    "\n",
    "            # Append the dictionary to the list\n",
    "            job_info_list.append(job_info)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "job_info_df = pd.DataFrame(job_info_list)\n",
    "job_info_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           0\n",
       "Webindex        0\n",
       "Category        0\n",
       "Company        89\n",
       "Description     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info_df.fillna('Others', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title          0\n",
       "Webindex       0\n",
       "Category       0\n",
       "Company        0\n",
       "Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info_df.to_csv(\"JobInfo.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6987179487179487\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.68      0.74      0.71        35\n",
      "       Engineering       0.56      0.96      0.71        46\n",
      "Healthcare_Nursing       0.97      0.88      0.92        40\n",
      "             Sales       1.00      0.11      0.21        35\n",
      "\n",
      "          accuracy                           0.70       156\n",
      "         macro avg       0.81      0.67      0.64       156\n",
      "      weighted avg       0.79      0.70      0.65       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the TF-IDF weighted vectors from Task 2\n",
    "tfidf_weighted_vectors = pd.read_csv(\"weighted_vectors.txt\", delimiter=\" \", header=None)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = tfidf_weighted_vectors.values\n",
    "y = job_info_df['Category']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report, we come to know that the model performs well for some categories (e.g., \"Healthcare_Nursing\") but struggles with others (e.g., \"Sales\"), where recall is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title-Only Model(Q2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title-Only Model Accuracy: 0.8653846153846154\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.72      0.89      0.79        35\n",
      "       Engineering       0.85      0.85      0.85        46\n",
      "Healthcare_Nursing       0.97      0.88      0.92        40\n",
      "             Sales       0.97      0.86      0.91        35\n",
      "\n",
      "          accuracy                           0.87       156\n",
      "         macro avg       0.88      0.87      0.87       156\n",
      "      weighted avg       0.88      0.87      0.87       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed job advertisements from Task 1\n",
    "preprocessed_ads = pd.read_csv(\"preprocessed_ads.csv\", header=None, names=[\"Webindex\", \"Description\"])\n",
    "\n",
    "# Load the job titles from your dataset (e.g., \"Title\" column)\n",
    "job_titles = job_info_df[\"Title\"]\n",
    "labels = job_info_df[\"Category\"]\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer for titles\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate TF-IDF weighted vectors for titles\n",
    "title_tfidf_vectors = tfidf_vectorizer.fit_transform(job_titles)\n",
    "\n",
    "# Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(title_tfidf_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a logistic regression model\n",
    "title_model = LogisticRegression()\n",
    "\n",
    "# Train the model on the title vectors\n",
    "title_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "title_predictions = title_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "title_accuracy = accuracy_score(y_test, title_predictions)\n",
    "print(f\"Title-Only Model Accuracy: {title_accuracy}\")\n",
    "print(classification_report(y_test, title_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title and Description Model(Q2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title and Description Model Accuracy: 0.9166666666666666\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.82      0.94      0.88        35\n",
      "       Engineering       0.92      0.96      0.94        46\n",
      "Healthcare_Nursing       0.97      0.95      0.96        40\n",
      "             Sales       0.97      0.80      0.88        35\n",
      "\n",
      "          accuracy                           0.92       156\n",
      "         macro avg       0.92      0.91      0.91       156\n",
      "      weighted avg       0.92      0.92      0.92       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate job titles and descriptions\n",
    "combined_text = job_titles + \" \" + preprocessed_ads[\"Description\"]\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer for the combined text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate TF-IDF weighted vectors for the combined text\n",
    "combined_tfidf_vectors = tfidf_vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_tfidf_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a logistic regression model\n",
    "combined_model = LogisticRegression()\n",
    "\n",
    "# Train the model on the combined vectors\n",
    "combined_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "combined_predictions = combined_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "combined_accuracy = accuracy_score(y_test, combined_predictions)\n",
    "print(f\"Title and Description Model Accuracy: {combined_accuracy}\")\n",
    "print(classification_report(y_test, combined_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file using pickle\n",
    "with open('combined_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(combined_model, model_file)\n",
    "\n",
    "# Save the vectorizer during training\n",
    "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(tfidf_vectorizer, vectorizer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy increased from 70% to 91.7%.\n",
    "* Precision, recall, and F1-score values for each category have also improved, suggesting that the model is better at correctly classifying job advertisements into their respective categories.\n",
    "\n",
    "Based on these results, it's clear that incorporating additional information, such as the job title, can be highly beneficial for improving the accuracy of the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "#### Task 2 Generating Feature Representations for Job Advertisement Descriptions:\n",
    "\n",
    "* Feature Representations:\n",
    "\n",
    "    * Bag-of-Words (Count Vectors): Count vector representations were generated for each job advertisement based on the vocabulary.\n",
    "    * Word Embeddings: Word embeddings (TF-IDF weighted and unweighted) were generated using a pre-trained word embedding model using Word2Vec.\n",
    "\n",
    "* Evaluation: The feature representations were used to train and evaluate machine learning models for classifying job advertisements into categories.\n",
    "\n",
    "#### Task 3: Classification of Job Advertisements:\n",
    "\n",
    "Task 3 aimed to build machine learning models for classifying job advertisements into categories. This task involved:\n",
    "\n",
    "* Training Data: Using the feature representations generated in Task 2 and splitting the data into training and testing sets.\n",
    "* Model Building: Machine learning models, such as logistic regression, were trained on the training data using different sets of features:\n",
    "* Title-Only Model: Only job titles were used as features.\n",
    "* Description-Only Model: Only job descriptions were used as features.\n",
    "* Title and Description Model: Both job titles and descriptions were used as features, either concatenated or separately.\n",
    "* Model Evaluation: The models were evaluated using accuracy and classification metrics (precision, recall, F1-score) to determine their performance in classifying job advertisements.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "* Task 2 focused on feature representation, including count vectors and word embeddings, to represent job advertisements.\n",
    "* Task 3 built machine learning models to classify job advertisements based on these features, comparing different approaches (title-only, description-only, and combined title-description) to find the best-performing model.\n",
    "* Combining title and description as features led to the highest accuracy and improved precision, recall, and F1-score, demonstrating that additional information can enhance model accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
